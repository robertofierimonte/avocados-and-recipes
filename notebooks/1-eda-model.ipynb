{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avocados Technical Task - EDA and Model\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we explore the data, perform the feature engineering, and test the model that we built in Numpy.\n",
    "\n",
    "### Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set parent folder as root to import local modules\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "# Remove default logger and set level to INFO\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "from src.base.model import LinearRegression, rmse, r2\n",
    "from src.base.preprocessing import RepeatingRadialBasisFunction, sin_transformer, cos_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(module_path, \"data\")\n",
    "df = pd.read_csv(os.path.join(data_path, \"avocado.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of a mix of numerical and categorical variables. It also includes temporal information in the form of date and year. The dates are read as strings so we cast them to pandas datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing useless columns\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "# Converting dates from strings to datetime objects\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some checks on the size of the data\n",
    "logger.info(f\"Dataset shape: {df.shape} .\")\n",
    "logger.info(f\"\"\"Dataset number unique dates: {df[\"Date\"].nunique()} .\"\"\")\n",
    "logger.info(f\"\"\"Dataset number unique regions: {df[\"region\"].nunique()} .\"\"\")\n",
    "logger.info(f\"\"\"Dataset number unique types: {df[\"type\"].nunique()} .\"\"\")\n",
    "logger.info(f\"Dataset unique values: {df.drop_duplicates().shape} .\")\n",
    "logger.info(\n",
    "    f\"\"\"Dataset min date: {df[\"Date\"].min().date()} \"\"\"\n",
    "    f\"\"\"and max date: {df[\"Date\"].max().date()} .\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Total Bags` column seems to be a linear combination of the other columns that are related to the number of bags. If this is the case, we must drop this column otherwise the collinearity might cause issues with the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Delta\"] = np.abs(df[\"Total Bags\"] - (df[\"Small Bags\"] + df[\"Large Bags\"] + df[\"XLarge Bags\"]))\n",
    "max_delta = df[\"Delta\"].max()\n",
    "logger.info(\n",
    "    f\"\"\"Largest difference between column `Total Bags` and sum of columns \"\"\"\n",
    "    f\"\"\"`Small Bags`, `Large Bags`, and `XLarge Bags`: {max_delta:,.2f} .\"\"\"\n",
    ")\n",
    "df.drop(columns=[\"Total Bags\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cart_prod = df[\"Date\"].nunique() * df[\"type\"].nunique() * df[\"region\"].nunique()\n",
    "    assert(df.shape[0] == cart_prod)\n",
    "except AssertionError:\n",
    "    logger.warning(\n",
    "        f\"\"\"The lenght of the dataframe ({(df.shape[0]):,.0f}) is different \"\"\"\n",
    "        f\"\"\"from the that of the cartesian product of `Date`, `type`, and `region` \"\"\"\n",
    "        f\"\"\"({cart_prod:,.0f}) .\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"region\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[\n",
    "    (df[\"Date\"] == pd.Timestamp(\"2015-12-27\")) & \n",
    "    (df[\"type\"] == \"conventional\")\n",
    "]\n",
    "logger.info(f\"\"\"Number of regions in the sample dataset: {df_test[\"region\"].nunique()} .\"\"\")\n",
    "logger.info(\n",
    "    f\"\"\"The combined toal volume across all regions apart from TotalUS is: \"\"\"\n",
    "    f\"\"\"{df_test[df_test[\"region\"] != \"TotalUS\"][\"Total Volume\"].sum():,.2f} .\"\"\"\n",
    ")\n",
    "logger.info(\n",
    "    f\"\"\"The total volumefor region TotalUS is: \"\"\"\n",
    "    f\"\"\"{df_test[df_test[\"region\"] == \"TotalUS\"][\"Total Volume\"].sum():,.2f} .\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we check for any missing date values and inconsistencies between the date and the year. We also check whether the `year` has any impact on the price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any missing date\n",
    "sorted_dates = sorted(df[\"Date\"].unique())\n",
    "for i in range(df[\"Date\"].nunique() - 1):\n",
    "    dt_c, dt_n = sorted_dates[i], sorted_dates[i + 1]\n",
    "    if dt_c + pd.Timedelta(days=7) != dt_n:\n",
    "        logger.error(f\"Error: date missing {format(dt_c + pd.Timedelta(days=7))} .\")\n",
    "\n",
    "# Check for any inconsistencies between date and year\n",
    "if (df[\"Date\"].dt.year == df[\"year\"]).min() is False:\n",
    "    logger.error(\"Error: Dates and years not matching.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = sorted(df[\"year\"].unique())\n",
    "\n",
    "avgs = df.groupby(\"year\").agg({\"AveragePrice\": \"mean\"}).to_dict()[\"AveragePrice\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 4))\n",
    "ax.boxplot([df[df[\"year\"] == y][\"AveragePrice\"].values for y in years])\n",
    "ax.scatter(y=[avgs[y] for y in years], x=np.arange(1, len(years) + 1), marker='*')\n",
    "\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Avocados Prices\")\n",
    "ax.set_xticklabels(years)\n",
    "fig.suptitle(\"Avocados prices statistics by year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Here we perform the feature engineering. \n",
    "\n",
    "- `AveragePrice` will be our target variable\n",
    "- For the numerical features, we transform them by subtracting the mean and dividing by the standard deviation\n",
    "- For the categorical features, we transform them to binary values using One Hot encoding:\n",
    "     *  `type` has only two values so it's fine to just encode it as binary\n",
    "     *  `region` has 54 distinct values so we need to do a bit more processing\n",
    "     \n",
    "     <br/>\n",
    "- For the date features, we use repeating encodings to account for the seasonality of month and week of the year. As we observed earlier the year does not play a big factor in this dataset so we decide to drop it\n",
    "     - We transform the month of the year using repeating radial basis functions\n",
    "     - We transform the week of the year using the sine / cosine transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"AveragePrice\"\n",
    "num_cols = [c for c in df.columns if df[c].dtype == \"float64\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be our target variable\n",
    "y = df[target_col].values\n",
    "logger.info(f\"y shape: {y.shape} .\")\n",
    "\n",
    "# For the numerical volumns, we transform them by subtracting the mean and \n",
    "# dividing by the standard deviation\n",
    "X_num = df[num_cols].values\n",
    "X_num = (X_num - np.mean(X_num, axis=0)) / np.std(X_num, axis=0)\n",
    "logger.info(f\"X_num shape: {X_num.shape} .\")\n",
    "\n",
    "# For the categorical columns, we transform them to binary values using One Hot \n",
    "# encoding. `type` has only two values so it's fine to just encode it as binary, \n",
    "# while for `region` we need to do a bit more processing\n",
    "X_type = df[\"type\"].map(dict(zip(df[\"type\"].unique(), np.arange(2)))).values\n",
    "X_type = np.expand_dims(X_type, axis=-1)\n",
    "logger.info(f\"X_type shape: {X_type.shape} .\")\n",
    "\n",
    "n_regs = df[\"region\"].nunique() # 54 \n",
    "# We could have even used 53 as one column is redundant\n",
    "target_regs = df[\"region\"].map(dict(zip(df[\"region\"].unique(), np.arange(n_regs)))).values\n",
    "X_region = np.eye(n_regs)[target_regs]\n",
    "logger.info(f\"X_region shape: {X_region.shape} .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the dates, we choose to encode them in different ways:\n",
    "# - First as we saw earlier we don't need the year column as \n",
    "# - Then we transform the month of the year using repeating radial basis functions\n",
    "# - Then we transform the week of the year using the sine / cosine transformations\n",
    "df[\"DoY\"] = df[\"Date\"].dt.day_of_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_month = RepeatingRadialBasisFunction(n_periods=12)\n",
    "rbf_month.fit(X=df[\"DoY\"])\n",
    "X_month = rbf_month.transform(df[\"DoY\"])\n",
    "logger.info(f\"X_month shape: {X_month.shape} .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pd.DataFrame(index=df[\"Date\"].values, data=X_month).plot(\n",
    "    subplots=True, figsize=(16, 8), sharex=True, legend=False, ylim=(0, 1),\n",
    "    title=\"Repeating Radial Basis Functions\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sin = sin_transformer(df[\"DoY\"].values, period=52)\n",
    "X_cos = cos_transformer(df[\"DoY\"].values, period=52)\n",
    "X_week = np.concatenate([X_sin[:, np.newaxis], X_cos[:, np.newaxis]], axis=1)\n",
    "logger.info(f\"X_week shape: {X_week.shape} .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pd.DataFrame(index=df[\"Date\"].values, data=X_week, columns=['sin', 'cos']).plot(\n",
    "    subplots=False, figsize=(16, 4), legend=True, ylim=(-1, 1),\n",
    "    title=\"Sine / Cosine transformation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and testing\n",
    "\n",
    "Here we create, train, and test our Numpy Linear Regression model. \n",
    "\n",
    "We start by concatenating all the features that we have engineered into a single Numpy array. We then split the data into training and testing sets, and we use the training set to train the model and the testing set to evaluate the model. \n",
    "\n",
    "Given that we are training a linear model for regression, we choose the `Root Mean Squared Error (RMSE)` and the `R^2` as our evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X_num, X_type, X_region, X_month, X_week], axis=1)\n",
    "logger.info(f\"X shape: {X.shape} .\")\n",
    "\n",
    "train_idx = np.random.choice(X.shape[0], int(0.8 * X.shape[0]), replace=False)\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "logger.info(f\"X_train shape: {X_train.shape} , y_train shape: {y_train.shape} .\")\n",
    "\n",
    "test_mask = np.ones((X.shape[0]), dtype=bool)\n",
    "test_mask[train_idx] = False\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "logger.info(f\"X_test shape: {X_test.shape} , y_test shape: {y_test.shape} .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_ = rmse(y_test, y_preds)\n",
    "r2_ = r2(y_test, y_preds)\n",
    "logger.info(f\"Model RMSE: {rmse_:,.2f}, R^2: {r2_:,.2f} .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('avocados-technical-task-VZNvEIBl-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fe8e8c863cf8003bf374e57b207e421569f7157c71ce0e42d39ae721c20d50d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
